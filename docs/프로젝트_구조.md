# 한라챗봇 프로젝트 구조

이 문서는 한라대학교 챗봇 프로젝트의 전체 구조와 각 파일의 역할을 설명합니다.

> **최근 업데이트**: 2025-10-10  
> **변경 사항**: RAG 모듈 분리 완료 (Phase 2), JSON Lines 스트리밍 도입, 메타데이터 시스템 강화

---

## 1. 프로젝트 개요

이 프로젝트는 한라대학교의 학사 정보, 규정, 학교 생활 관련 정보 등을 제공하는 AI 챗봇 시스템입니다. FastAPI 웹 서버를 기반으로 OpenAI GPT 모델을 활용하여 사용자 질의에 응답합니다. 주요 기능으로는:

- **실시간 스트리밍 대화**: JSON Lines 포맷으로 텍스트를 실시간 전송
- **모듈형 RAG 시스템**: 학사 규정 검색 및 답변 (5단계 파이프라인)
- **메타데이터 제공**: RAG 출처, 함수 호출 정보 등을 클라이언트에 전달
- **실시간 웹 검색**: DuckDuckGo 기반 웹검색
- **학식 메뉴 조회**: 한라대 학생식당 메뉴 크롤링
- **다국어 지원**: 8개 언어 지원 (한국어, 영어, 베트남어 등)

## 2. 폴더 구조

```
/app
├── api/                      # API 라우터 모듈
│   └── routes.py             # FastAPI 라우트 정의
├── ai/                       # AI 관련 모듈 (NEW)
│   ├── chatbot/              # 챗봇 핵심 로직
│   │   ├── config.py         # OpenAI 클라이언트 설정
│   │   ├── metadata.py       # 메타데이터 구조 (RagMetadata 등)
│   │   └── stream.py         # ChatbotStream 클래스 (통합 스트리밍)
│   ├── functions/            # 함수 호출 모듈
│   │   └── analyzer.py       # FunctionCalling 클래스
│   ├── rag/                  # RAG 모듈 (Phase 2: 모듈 분리)
│   │   ├── __init__.py       # 퍼블릭 API 정의
│   │   ├── gate.py           # RegulationGate (규정 질문 판단)
│   │   ├── retriever.py      # PineconeRetriever (벡터 검색)
│   │   ├── repository.py     # MongoChunkRepository (문서 조회)
│   │   ├── RagDocumentPackage.py  # ContextBuilder (문서 조립)
│   │   └── service.py        # RagService (RAG 오케스트레이션)
│   └── data/                 # 데이터 접근 계층
│       ├── mongodb_client.py # MongoDB 연결
│       └── vector_uploader.py # Pinecone 임베딩 업로드
├── loding/                   # 데이터 로딩 모듈
│   ├── documentLoding.py     # 문서 로딩 및 청킹
│   └── mongodbConnect.py     # MongoDB 연결 (레거시)
├── pdfs/                     # 학사 규정 문서 저장 디렉토리
│   └── (다수의 hwp/hwpx 파일들)
├── docs/                     # 프로젝트 문서
│   ├── README.md             # 문서 목록
│   ├── 프로젝트_구조.md      # 이 문서
│   ├── 프론트엔드_API_통합_가이드.md  # 프론트엔드 개발자용
│   └── ...
├── main.py                   # FastAPI 메인 애플리케이션
├── apikey.env                # API 키 환경 변수
├── requirements.txt          # 의존성 패키지 목록
└── test_stream_chat.py       # 스트리밍 테스트 클라이언트
```

## 3. 주요 모듈 설명

### 3.1 API 모듈 (`/api`)

#### routes.py
- FastAPI 라우트 정의
- `/api/chat` - JSON Lines 스트리밍 방식 채팅 응답
- **핵심 책임**:
  - HTTP 요청/응답 처리
  - ChatbotStream 인스턴스 생성 및 호출
  - 스트리밍 응답 전달

---

### 3.2 AI 모듈 (`/ai`) ⭐ **Phase 2: 신규 구조**

#### 📁 `/ai/chatbot` - 챗봇 핵심 로직

##### stream.py
- **`ChatbotStream` 클래스** - 챗봇의 통합 스트리밍 로직
- **핵심 메서드**:
  - `stream_chat()`: 9단계 통합 처리 (메시지 추가 → RAG → 함수 호출 → 스트리밍 → 메타데이터 전송)
  - `_condense_rag_context()`: RAG 컨텍스트 요약
  - `_build_final_context()`: 최종 프롬프트 구성
  - `_analyze_and_execute_functions()`: 함수 호출 분석/실행
  - `_stream_openai_response()`: OpenAI API 스트리밍 호출
- **책임**:
  - 대화 컨텍스트 관리
  - RAG 서비스 호출
  - 함수 호출 오케스트레이션
  - JSON Lines 스트리밍 응답 생성
  - 메타데이터 조립 및 전송

##### metadata.py
- **메타데이터 구조 정의** (dataclass)
  - `RagMetadata`: RAG 검색 정보 (is_regulation, source_documents 등)
  - `FunctionCallMetadata`: 함수 호출 정보
  - `ChatMetadata`: 전체 메타데이터 통합
- **책임**: 클라이언트에 전달할 메타데이터 직렬화

##### config.py
- OpenAI 클라이언트 설정
- 모델 ID 관리

---

#### 📁 `/ai/rag` - RAG 모듈 (Phase 2: 모듈 분리)

**설계 철학**: 단일 책임 원칙 + 레이어드 아키텍처

##### service.py
- **`RagService` 클래스** - RAG 전체 오케스트레이션
- **5단계 RAG 파이프라인**:
  1. Gate: 규정 질문 판단
  2. Retriever: Pinecone 벡터 검색
  3. Repository: MongoDB 문서 조회
  4. Context Builder: 문서 조립
  5. Result: 최종 결과 반환
- **핵심 메서드**:
  - `retrieve_context(question)`: 통합 RAG 처리
- **책임**: RAG 컴포넌트 조율

##### gate.py
- **`RegulationGate` 클래스** - 규정 질문 판단
- **책임**: 질문이 학사 규정 관련인지 LLM 기반 판단
- **반환**: `GateDecision` (is_regulation, reason)

##### retriever.py
- **`PineconeRetriever` 클래스** - 벡터 검색
- **책임**: Pinecone에서 유사 문서 검색
- **반환**: `RetrieverResult` (hits, chunk_ids)

##### repository.py
- **`MongoChunkRepository` 클래스** - 문서 저장소
- **책임**: MongoDB에서 문서 조각 조회
- **반환**: 문서 목록 (list of dict)

##### RagDocumentPackage.py (context_builder.py)
- **`ContextBuilder` 클래스** - 문서 조립기
- **책임**:
  - MongoDB 문서를 `\n\n`로 병합
  - 메타데이터 추출 (law_article_id, source_file, title)
  - Fallback: Pinecone 미리보기 사용
- **반환**: `RagDocumentPackage` (merged_documents_text, source_documents 등)

##### __init__.py
- **퍼블릭 API 정의**
- 외부에서 `from ai.rag import RagService` 형태로 import

---

#### 📁 `/ai/functions` - 함수 호출 모듈

##### analyzer.py
- **`FunctionCalling` 클래스** - 함수 호출 분석 및 실행
- **핵심 메서드**:
  - `analyze(message, tools)`: 사용자 메시지 분석
  - 함수 실행 로직
- **책임**: 필요한 함수 판단 및 실행

---

#### 📁 `/ai/data` - 데이터 접근 계층

##### mongodb_client.py
- MongoDB 연결 설정
- `collection` 객체 제공

##### vector_uploader.py
- Pinecone 임베딩 생성 및 업로드
- 대규모 문서 처리 최적화

---

### 3.3 레거시 모듈 (`/chatbotDirectory`)

> **참고**: 점진적으로 `/ai` 모듈로 마이그레이션 중

#### functioncalling.py
- **함수 구현** (실제 로직)
  - `search_internet()`: 웹검색 (DuckDuckGo)
  - `get_halla_cafeteria_menu()`: 학식 메뉴 크롤링
- **책임**: 함수의 실제 구현부

#### character.py
- 챗봇 캐릭터 프롬프트
- 시스템 역할 정의

#### common.py
- 공통 유틸리티 함수
- 모델 설정

---

### 3.4 데이터 로딩 모듈 (`/loding`)

#### documentLoding.py
- **문서 로딩 및 청킹**
- **청킹 전략**:
  - 조항 단위: `extract_chunks_finditer()`
  - 별표 단위: `extract_star_tables()`
- **책임**: HWP 파일 파싱 및 구조화

#### mongodbConnect.py (레거시)
- MongoDB 연결 (레거시)
- 문서 삽입 로직

---

### 3.5 메인 애플리케이션 (`main.py`)
- FastAPI 애플리케이션 설정
- CORS 미들웨어 설정
- API 라우터 등록 (`/api` prefix)

## 4. 데이터 흐름

### 4.1 전체 스트리밍 플로우 (JSON Lines)

```
클라이언트 요청
    ↓
[routes.py] - FastAPI 엔드포인트 (/api/chat)
    ↓
[ChatbotStream.stream_chat()] - 9단계 통합 처리
    ├─ 1. 메시지 추가
    ├─ 2-6. RAG 처리 (5단계 파이프라인)
    │   ├─ Gate: 규정 질문 판단
    │   ├─ Retriever: Pinecone 벡터 검색
    │   ├─ Repository: MongoDB 문서 조회
    │   ├─ Context Builder: 문서 조립
    │   └─ Result: RagResult 반환
    ├─ 7. 함수 호출 분석/실행 (필요 시)
    ├─ 8. OpenAI API 스트리밍 호출
    │   └─ JSON Lines 스트리밍: {"type":"delta","content":"안"}
    │                            {"type":"delta","content":"녕"}
    └─ 9. 메타데이터 전송
        └─ JSON Lines: {"type":"metadata","metadata":{...}}
    ↓
클라이언트 응답 (JSON Lines 파싱)
```

---

### 4.2 RAG 5단계 파이프라인 (Phase 2)

```python
# RagService.retrieve_context(question) 내부

1️⃣ Gate Layer (규정 질문 판단)
   RegulationGate.should_use_rag(question)
   → GateDecision (is_regulation: bool, reason: str)

2️⃣ Retriever Layer (벡터 검색)
   PineconeRetriever.search(question, top_k=10)
   → RetrieverResult (hits: List[dict], chunk_ids: List[str])

3️⃣ Repository Layer (문서 조회)
   MongoChunkRepository.find_by_ids(chunk_ids)
   → documents: List[dict]

4️⃣ Context Builder Layer (문서 조립)
   ContextBuilder.build(documents, retriever_result)
   → RagDocumentPackage (
       merged_documents_text: str,
       source_documents: List[SourceDocument],
       ...
     )

5️⃣ Service Layer (최종 결과)
   RagService._make_result(gate_decision, rag_package)
   → RagResult (
       is_regulation: bool,
       merged_documents_text: str,
       source_documents: List[SourceDocument],
       regulation_check_reason: str
     )
```

---

### 4.3 스트리밍 응답 형식 (JSON Lines)

클라이언트는 HTTP Chunked Transfer Encoding으로 받음:

```jsonlines
{"type":"delta","content":"안"}
{"type":"delta","content":"녕"}
{"type":"delta","content":"하"}
{"type":"delta","content":"세"}
{"type":"delta","content":"요"}
{"type":"metadata","metadata":{"rag":{"is_regulation":true,"source_documents":[...],"merged_documents_text":"..."},"functions":null,"web_search_status":null}}
{"type":"done"}
```

각 줄은 독립적인 JSON 객체:
- **delta**: 스트리밍 응답 조각
- **metadata**: RAG/함수 호출 정보
- **done**: 응답 완료 신호

> **자세한 내용**: `docs/프론트엔드_API_통합_가이드.md` 참조

---

### 4.4 MongoDB 문서 조립 (ContextBuilder)

```python
# RagDocumentPackage.py - ContextBuilder.build()

1. MongoDB 문서 조회 성공:
   documents = [
       {"text": "제1조 목적...", "law_article_id": "3-1-1#1", ...},
       {"text": "제2조 정의...", "law_article_id": "3-1-1#2", ...}
   ]
   
2. 텍스트 추출:
   extracted_texts = ["제1조 목적...", "제2조 정의..."]
   
3. 병합:
   merged_documents_text = "제1조 목적...\n\n제2조 정의..."
   
4. 메타데이터 추출:
   source_documents = [
       SourceDocument(
           law_article_id="3-1-1#1",
           source_file="교원 인사 규정",
           title="제1조 목적"
       ),
       ...
   ]

5. Fallback (MongoDB 실패 시):
   - Pinecone hit의 metadata.text 사용
   - 일반 텍스트 병합
```

---

### 4.5 함수 호출 플로우

```
1. ChatbotStream._analyze_and_execute_functions()
   ↓
2. FunctionCalling.analyze(message, tools)
   - OpenAI 함수 호출 API 사용
   - 필요한 함수 판단
   ↓
3. 함수 실행
   - search_internet() → DuckDuckGo API 호출
   - get_halla_cafeteria_menu() → 웹 크롤링
   ↓
4. 함수 결과를 메시지 히스토리에 추가
   ↓
5. 메타데이터에 함수 정보 기록
   - FunctionCallMetadata (function_name, args, result)
```

## 5. 주요 기술 스택

- **백엔드**: Python 3.13, FastAPI
- **AI 모델**: OpenAI GPT (gpt-4.1, gpt-4o)
- **스트리밍 프로토콜**: JSON Lines (NDJSON)
- **벡터 DB**: Pinecone
- **문서 DB**: MongoDB
- **임베딩**: OpenAI text-embedding-3-small
- **기타 라이브러리**:
  - BeautifulSoup (웹 스크래핑)
  - tiktoken (토큰 관리)
  - llama-index (문서 처리)
  - requests (HTTP 클라이언트)

### 5.1 아키텍처 패턴
- **레이어드 아키텍처**: API → Service → Repository
- **단일 책임 원칙**: 각 모듈은 하나의 책임만 수행
- **의존성 역전**: 인터페이스 기반 설계 (추상화)
- **스트리밍 퍼스트**: 실시간 응답 우선 설계

### 5.2 데이터 흐름 패턴
- **파이프라인 패턴**: RAG 5단계 처리
- **메타데이터 패턴**: 응답과 분리된 부가 정보 제공
- **Fallback 패턴**: MongoDB 실패 시 Pinecone 사용
